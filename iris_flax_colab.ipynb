{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92057d79",
   "metadata": {},
   "source": [
    "# Iris Classification using Flax Neural Network\n",
    "\n",
    "This notebook implements a 2-layer feedforward neural network using Flax to classify the Iris dataset. We'll use JAX for efficient numerical computations and Flax for neural network layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97600357",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "First, let's install the required packages. We'll need JAX, Flax, and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install flax optax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe2b4c",
   "metadata": {},
   "source": [
    "## Import Dependencies\n",
    "\n",
    "Now let's import all the necessary libraries for our neural network implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2349a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "from flax.training import train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b8c8b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Let's load and preprocess the Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c11bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the Iris dataset\n",
    "data = load_iris()\n",
    "X = data['data']\n",
    "y = data['target'].reshape(-1, 1)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# One-hot encode the labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f94bff",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Now we'll define our 2-layer feedforward neural network using Flax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    hidden_dim: int = 32\n",
    "    output_dim: int = 3\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(self.hidden_dim)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(self.output_dim)(x)\n",
    "        return x\n",
    "\n",
    "# Create a training state\n",
    "def create_train_state(rng, learning_rate, model):\n",
    "    params = model.init(rng, jnp.ones([1, 4]))['params']\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "# Define the loss function\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    return optax.softmax_cross_entropy(logits, labels).mean()\n",
    "\n",
    "def compute_metrics(logits, labels):\n",
    "    loss = cross_entropy_loss(logits, labels)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == jnp.argmax(labels, -1))\n",
    "    return {'loss': loss, 'accuracy': accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d258b7",
   "metadata": {},
   "source": [
    "## Training Functions\n",
    "\n",
    "Let's define the training and evaluation steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd6f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, batch['X'])\n",
    "        loss = cross_entropy_loss(logits, batch['y'])\n",
    "        return loss, logits\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    metrics = compute_metrics(logits, batch['y'])\n",
    "    return state, metrics\n",
    "\n",
    "# Evaluation step\n",
    "@jax.jit\n",
    "def eval_step(state, batch):\n",
    "    logits = state.apply_fn({'params': state.params}, batch['X'])\n",
    "    return compute_metrics(logits, batch['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282596e8",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Now let's train the model and visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training state\n",
    "rng = jax.random.PRNGKey(0)\n",
    "model = FeedForwardNN()\n",
    "state = create_train_state(rng, 0.001, model)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "num_train = X_train.shape[0]\n",
    "\n",
    "# Lists to store metrics for plotting\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    perm = jax.random.permutation(jax.random.PRNGKey(epoch), num_train)\n",
    "    batch_losses = []\n",
    "    batch_accuracies = []\n",
    "    \n",
    "    for i in range(0, num_train, batch_size):\n",
    "        idx = perm[i:i+batch_size]\n",
    "        batch = {\n",
    "            'X': jnp.array(X_train[idx]),\n",
    "            'y': jnp.array(y_train[idx])\n",
    "        }\n",
    "        state, metrics = train_step(state, batch)\n",
    "        batch_losses.append(metrics['loss'])\n",
    "        batch_accuracies.append(metrics['accuracy'])\n",
    "    \n",
    "    # Calculate average training metrics\n",
    "    avg_train_loss = np.mean(batch_losses)\n",
    "    avg_train_accuracy = np.mean(batch_accuracies)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(avg_train_accuracy)\n",
    "    \n",
    "    # Evaluation\n",
    "    test_batch = {\n",
    "        'X': jnp.array(X_test),\n",
    "        'y': jnp.array(y_test)\n",
    "    }\n",
    "    test_metrics = eval_step(state, test_batch)\n",
    "    test_losses.append(test_metrics['loss'])\n",
    "    test_accuracies.append(test_metrics['accuracy'])\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Accuracy: {avg_train_accuracy:.4f}\")\n",
    "        print(f\"Test Loss: {test_metrics['loss']:.4f}, Test Accuracy: {test_metrics['accuracy']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc52b3",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's plot the training and testing metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d01ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and testing loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and testing accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(test_accuracies, label='Testing Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Testing Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
